# -*- coding: utf-8 -*-
"""codsoft internship.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fqxZp5_HW6IzN5_Zu3EiCtwdK-FgVYnA

# **Titanic survival prediction**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data=pd.read_csv("Titanic-Dataset.csv")

data

data.shape

data.info()

data.isnull().sum()

data=data.drop(columns='Cabin',axis=1)

data['Age'].fillna(data['Age'].mean(),inplace=True)

data['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)

data['Fare'].fillna(data['Fare'].mode()[0],inplace=True)

data.isnull().sum().sum()

data['Survived'].value_counts()

data.describe()

sns.set()

sns.countplot(x='Survived',data=data)

sns.countplot(x='Survived',data=data)

sns.countplot(x='Sex',hue='Survived',data=data)

sns.countplot(x='Pclass',data=data)

sns.countplot(x='Pclass',hue='Survived',data=data)

data['Sex'].value_counts()

data['Embarked'].value_counts()

data.replace({'Sex':{'male':0,'female':1},'Embarked':{'S':0,'C':1,'Q':2}},inplace=True)

data

X=data.drop(columns=['PassengerId','Name','Ticket'],axis=1)

Y=data['Survived']

print(X)

print(Y)

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

model=LogisticRegression()

model.fit(X_train,Y_train)

X_train_prediction=model.predict(X_train)

print(X_train_prediction)

train_data_accuracy=accuracy_score(Y_train,X_train_prediction)

print("Accuracy Score of training data: ",train_data_accuracy)

X_test_prediction=model.predict(X_test)

print(X_test_prediction)

test_data_accuracy=accuracy_score(Y_test,X_test_prediction)

print("Accuracy score of testing data:",test_data_accuracy)

"""# Iris flower classification



"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

iris_flower_file=pd.read_csv("iris flower.csv")

iris_flower_file.head(16)

iris_flower_file.shape

iris_flower_file.info()

iris_flower_file.describe()

iris_flower_file.isnull().sum()

iris_flower_file.describe()

iris_flower_file['sepal_length'].hist()

iris_flower_file['sepal_width'].hist()

iris_flower_file['petal_length'].hist()

iris_flower_file['petal_width'].hist()

colors=['red','Black','teal']

species=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']

for i in range(3):
    x=iris_flower_file[iris_flower_file['species']==species[i]]
    plt.scatter(x['sepal_length'],x['sepal_width'],c=colors[i],label=species[i])
plt.xlabel("Sepal Length")
plt.ylabel("Sepal Width")
plt.legend()

for i in range(3):
    x=iris_flower_file[iris_flower_file['species']==species[i]]
    plt.scatter(x['petal_length'],x['petal_width'],c=colors[i],label=species[i])
plt.xlabel("Petal Length")
plt.ylabel("Petal Width")
plt.legend()

for i in range(3):
    x=iris_flower_file[iris_flower_file['species']==species[i]]
    plt.scatter(x['sepal_length'],x['petal_length'],c=colors[i],label=species[i])
plt.xlabel("Sepal Length")
plt.ylabel("Petal Length")
plt.legend()

for i in range(3):
    x=iris_flower_file[iris_flower_file['species']==species[i]]
    plt.scatter(x['sepal_width'],x['petal_width'],c=colors[i],label=species[i])
plt.xlabel("Sepal Width")
plt.ylabel("Petal Width")
plt.legend()

numeric_columns=iris_flower_file.drop(columns='species')
corr=numeric_columns.corr()
fig,axis=plt.subplots(figsize=(5,5))
sns.heatmap(corr,annot=True,ax=axis,cmap='coolwarm')

le=LabelEncoder()

iris_flower_file['species']=le.fit_transform(iris_flower_file['species'])

iris_flower_file.head(16)

x=iris_flower_file.drop(columns='species')

y=iris_flower_file['species']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)

LR=LogisticRegression()

LR.fit(x_train,y_train)

KNN=KNeighborsClassifier()

KNN.fit(x_train,y_train)

DT=DecisionTreeClassifier()

DT.fit(x_train,y_train)

LR_accuracy=LR.score(x_test,y_test)*100
KNN_accuracy=KNN.score(x_test,y_test)*100
DT_accuracy=DT.score(x_test,y_test)*100

print(f"Accuracy by using Logistic Regression: {LR_accuracy}%")

print(f"Accuracy by using K Nearest Neighbors Algorithm: {KNN_accuracy}%")

print(f"Accuracy by using Decision Tree Classifier: {DT_accuracy}%")

"""# Credit Card Fraud detection"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

file=pd.read_csv("credit card.csv")

file.head(10)

file.describe()

file.isnull().sum()

file['Class'].value_counts()

normal=file[file.Class==0]

fraud=file[file.Class==1]

print(normal.shape)

print(normal.shape)

normal.Amount.describe()

fraud.Amount.describe()

file.groupby('Class').mean()

normal_sample=normal.sample(n=492)

new_file=pd.concat([normal_sample,fraud],axis=0)

new_file.head(10)

new_file['Class'].value_counts()

new_file.groupby('Class').mean()

X=new_file.drop(columns='Class',axis=1)

Y=new_file['Class']

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

model=LogisticRegression()

model.fit(X_train,Y_train)

X_train_prediction=model.predict(X_train)

training_data_acuracy=accuracy_score(X_train_prediction,Y_train)*100

print(f"Training Data Accuracy: {training_data_acuracy}%")

X_test_prediction=model.predict(X_test)

test_data_accuracy=accuracy_score(X_test_prediction,Y_test)*100

print(f"Test Data Accuracy: {test_data_accuracy}%")

